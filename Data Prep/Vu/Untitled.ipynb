{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_blobs\n",
    "from collections import Counter\n",
    "from path import Path\n",
    "import hvplot.pandas\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "import mpu\n",
    "from uszipcode import SearchEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_schedule_data(df, df1):\n",
    "    \n",
    "    # pulling only the columns we want from the pitching log dataframe\n",
    "    df = df[[\"Game#\", \"Opp\", \"Result\", \"Starting Pitcher\", \"Opposing Pitcher\"]]\n",
    "    df.set_index(\"Game#\", inplace = True)\n",
    "    \n",
    "    # pulling only the columns we want from the schedule log dataframe\n",
    "    df1 = df1[[\"Hm/Aw\", \"Game#\"]]\n",
    "    df1.set_index(\"Game#\", inplace = True)\n",
    "    \n",
    "    # combining into one dataframe to work with\n",
    "    return_df = pd.merge(df, df1, left_index=True, right_index=True)\n",
    "    return_df.dropna(inplace=True)\n",
    "    \n",
    "    # changing results from W/L to 1/0\n",
    "    true_w = return_df[\"Result\"].str.contains('W', na=True)\n",
    "    binary_result = []\n",
    "    for row in return_df.index:\n",
    "        if true_w[row]:\n",
    "            binary_result.append(1)\n",
    "        else:\n",
    "            binary_result.append(0)\n",
    "        \n",
    "    return_df[\"Result\"] = binary_result\n",
    "    \n",
    "    \n",
    "    # getting the distance between thw two clubs\n",
    "    Home = []\n",
    "    Away = []\n",
    "    \n",
    "    x = len(return_df)\n",
    "    return_df.reset_index(inplace = True)\n",
    "    return_df.drop(columns = \"Game#\", inplace = True)\n",
    "    \n",
    "    for number in return_df.index:\n",
    "        if return_df.loc[number][\"Hm/Aw\"] == \"Away\":\n",
    "            Home.append(return_df.loc[number][\"Opp\"])\n",
    "            Away.append(\"HOU\")\n",
    "        else:\n",
    "            Home.append(\"HOU\")\n",
    "            Away.append(return_df.loc[number][\"Opp\"])\n",
    "            \n",
    "    return_df[\"Home\"] = Home\n",
    "    return_df[\"Away\"] = Away\n",
    "        \n",
    "    return_df[\"Distance\"] = [get_home_away_distance_in_miles(home, away) for home, away in zip(return_df.Home, return_df.Away)]\n",
    "\n",
    "    return_df['Distance'] = [distance * -1 if stadium == 'Home' else distance for stadium, \n",
    "                             distance in zip(return_df['Hm/Aw'], return_df['Distance'])]\n",
    "    \n",
    "    \n",
    "    # setting index and dropping off columns we don't need anymore\n",
    "    return_df.set_index(\"Opp\", inplace = True)\n",
    "    \n",
    "    return_df.drop(columns = [\"Hm/Aw\", \"Home\", \"Away\"], inplace = True)\n",
    "    \n",
    "    return return_df\n",
    "\n",
    "\n",
    "def clean_batting_data(df1):\n",
    "    \n",
    "    # dropping last two rows as they are average and total\n",
    "    df1.drop(index = [30, 31], inplace = True)\n",
    "    \n",
    "    # setting index to team name\n",
    "    df1.set_index(\"Tm\", inplace = True)\n",
    "    \n",
    "    # setting index to match for team acry df\n",
    "    team_acry.set_index(\"Team(Bat)\", inplace = True)\n",
    "    \n",
    "    # changing team names to match\n",
    "    new_team_name = []\n",
    "\n",
    "    for team in df1.index:\n",
    "        if team in team_acry.index:\n",
    "            new_team_name.append(team_acry.loc[team][\"Team(New)\"])\n",
    "            \n",
    "    df1.index = new_team_name\n",
    "    \n",
    "    # pulling only the metrics we want\n",
    "#     df1 = df1[[\"BatAge\", \"R/G\", \"PA\", \"AB\", \"H\", \"2B\", \"3B\", \"HR\", \"BB\", \"SO\", \"BA\", \"OBP\", \"SLG\", \"OPS\", \"TB\", \"HBP\", \"LOB\"]]\n",
    "    df1 = df1[[\"BatAge\", \"LOB\"]]\n",
    "\n",
    "    # resetting index for team acry df\n",
    "    team_acry.reset_index(inplace = True)\n",
    "    \n",
    "    # returning the dataframe\n",
    "    return df1\n",
    "\n",
    "\n",
    "def clean_pitching_data(df):\n",
    "    \n",
    "    # need to get rid of extra space in pitcher names\n",
    "    random_number = list(range(len(df)))\n",
    "    list_of_pitchers = []\n",
    "    for number in random_number:\n",
    "        string = df[\"Name\"][number] \n",
    "        string = string.replace(u'\\xa0', u' ')\n",
    "        list_of_pitchers.append(string)\n",
    "    df[\"Pitcher\"] = list_of_pitchers\n",
    "    \n",
    "    # setting index to pitchers\n",
    "    df = df.groupby(\"Pitcher\").mean()\n",
    "    \n",
    "    # pulling only the metrics we want\n",
    "    df = df[[\"ERA\", \"CG\", \"IP\", \"ERA+\", \"FIP\", \"WHIP\", \"H9\", \"HR9\", \"BB9\", \"SO9\", \"SO/W\"]]\n",
    "    \n",
    "    # returning the dataframe\n",
    "    return df\n",
    "\n",
    "def get_distance_in_miles(home_team_zip, away_team_zip):        \n",
    "    \n",
    "    #for extensive list of zipcodes, set simple_zipcode=False\n",
    "    search = SearchEngine(simple_zipcode=True)\n",
    "    zip1 = search.by_zipcode(home_team_zip)\n",
    "    zip2 = search.by_zipcode(away_team_zip)\n",
    "\n",
    "    return round(mpu.haversine_distance((zip1.lat, zip1.lng), (zip2.lat, zip2.lng)), 2)\n",
    "\n",
    "def get_home_away_distance_in_miles(home_team_code, away_team_code):\n",
    "    \n",
    "    teams = [\n",
    "        { 'team': 'ARI', 'name': 'Arizona Diamondbacks', 'address': '401 E Jefferson St, Phoenix, AZ 85004' },\n",
    "        { 'team': 'ATL', 'name': 'Atlanta Braves',  'address': '755 Battery Ave SE, Atlanta, GA 30339' },\n",
    "        { 'team': 'BAL', 'name': 'Baltimore Orioles', 'address': '333 W Camden St, Baltimore, MD 21201' },\n",
    "        { 'team': 'BOS', 'name': 'Boston Red Sox', 'address': '4 Jersey St, Boston, MA 02215' },\n",
    "        { 'team': 'CHA', 'name': 'Chicago White Sox', 'address': '333 W 35th St, Chicago, IL 60616'},\n",
    "        { 'team': 'CHN', 'name': 'Chicago Cubs', 'address': '1060 W Addison St, Chicago, IL 60613' },\n",
    "        { 'team': 'CIN', 'name': 'Cincinnati Reds', 'address': '100 Joe Nuxhall Way, Cincinnati, OH 45202' }, \n",
    "        { 'team': 'CLE', 'name': 'Cleveland Indians', 'address': '2401 Ontario St, Cleveland, OH 44115' },\n",
    "        { 'team': 'COL', 'name': 'Colorado Rockies', 'address': '2001 Blake St, Denver, CO 80205' },\n",
    "        { 'team': 'DET', 'name': 'Detroit Tigers', 'address': '2100 Woodward Ave, Detroit, MI 48201' },\n",
    "        { 'team': 'HOU', 'name': 'Houston Astros', 'address': '501 Crawford St, Houston, TX 77002' },\n",
    "        { 'team': 'KCA', 'name': 'Kansas City Royals', 'address': '1 Royal Way, Kansas City, MO 64129' },\n",
    "        { 'team': 'ANA', 'name': 'Los Angeles Angels', 'address': '2000 E Gene Autry Way, Anaheim, CA 92806' },\n",
    "        { 'team': 'LAN', 'name': 'Los Angeles Dodgers', 'address': '1000 Vin Scully Ave, Los Angeles, CA 90012' },\n",
    "        { 'team': 'MIA', 'name': 'Miami Marlins', 'address': '501 Marlins Way, Miami, FL 33125' },\n",
    "        { 'team': 'MIL', 'name': 'Milwaukee Brewers', 'address': '1 Brewers Way, Milwaukee, WI 53214' },\n",
    "        { 'team': 'MIN', 'name': 'Minnesota Twins', 'address': '1 Twins Way, Minneapolis, MN 55403' },\n",
    "        { 'team': 'NYA', 'name': 'New York Yankees', 'address': '1 E 161 St, The Bronx, NY 10451' },\n",
    "        { 'team': 'NYN', 'name': 'New York Mets', 'address': '41 Seaver Way, Queens, NY 11368' },\n",
    "        { 'team': 'OAK', 'name': 'Oakland Athletics', 'address': '7000 Coliseum Way, Oakland, CA 94621' },\n",
    "        { 'team': 'PHI', 'name': 'Philadelphia Phillies', 'address': '1 Citizens Bank Way, Philadelphia, PA 19148' },\n",
    "        { 'team': 'PIT', 'name': 'Pittsburgh Pirates', 'address': '115 Federal St, Pittsburgh, PA 15212' },\n",
    "        { 'team': 'SDN', 'name': 'San Diego Padres', 'address': '100 Park Blvd, San Diego, CA 92101' },\n",
    "        { 'team': 'SFN', 'name': 'San Francisco Giants', 'address': '24 Willie Mays Plaza, San Francisco, CA 94107' },\n",
    "        { 'team': 'SEA', 'name': 'Seattle Mariners', 'address': '1250 1st Ave S, Seattle, WA 98134' },\n",
    "        { 'team': 'SLN', 'name': 'St. Louis Cardinals', 'address': '700 Clark Ave, St. Louis, MO 63102' },\n",
    "        { 'team': 'TBA', 'name': 'Tampa Bay Rays', 'address': '1 Tropicana Dr., St. Petersburg, FL 33705' },\n",
    "        { 'team': 'TEX', 'name': 'Texas Rangers', 'address': '734 Stadium Dr, Arlington, TX 76011' },\n",
    "        { 'team': 'TOR', 'name': 'Toronto Blue Jays', 'address': '1 Blue Jays Way, Toronto, ON 14305' },\n",
    "        { 'team': 'WAS', 'name': 'Washington Nationals', 'address': '1500 S Capitol St SE, Washington, DC 20003' }\n",
    "    ]\n",
    "\n",
    "    teams_zip_df = pd.DataFrame.from_dict(teams)\n",
    "\n",
    "    teams_zip_df['zip'] = teams_zip_df['address'].str.split(',', expand=True)[2].str.split(' ', expand=True)[2]\n",
    "    teams_zip_df.sort_values(\"team\", inplace=True) \n",
    "    teams_zip_df.set_index('team', inplace=True)    \n",
    "        \n",
    "    return get_distance_in_miles(\n",
    "        home_team_zip = teams_zip_df.loc[home_team_code]['zip'], \n",
    "        away_team_zip = teams_zip_df.loc[away_team_code]['zip'])\n",
    "\n",
    "def combine_year_df(df_result_schedule, df_bat, df_pitch, team):\n",
    "        \n",
    "    # gathering Houston Astros batting averages\n",
    "#     df_team = df_bat.loc[team]\n",
    "#     df_team = pd.DataFrame(df_team)\n",
    "#     df_team = df_team.transpose()\n",
    "#     df_team.rename(columns = {\n",
    "#         \"BatAge\" : \"Favorite-BatAge\", \n",
    "#         \"R/G\" : \"Favorite-R/G\", \n",
    "#         \"PA\" : \"Favorite-PA\", \n",
    "#         \"AB\" : \"Favorite-AB\", \n",
    "#         \"H\" : \"Favorite-H\", \n",
    "#         \"2B\" : \"Favorite-2B\", \n",
    "#         \"3B\" : \"Favorite-3B\", \n",
    "#         \"HR\" : \"Favorite-HR\",\n",
    "#         \"BB\" : \"Favorite-BB\", \n",
    "#         \"SO\" : \"Favorite-SO\", \n",
    "#         \"BA\" : \"Favorite-BA\", \n",
    "#         \"OBP\" : \"Favorite-OBP\", \n",
    "#         \"SLG\" : \"Favorite-SLG\", \n",
    "#         \"OPS\" : \"Favorite-OPS\", \n",
    "#         \"TB\" : \"Favorite-TB\", \n",
    "#         \"HBP\" : \"Favorite-HBP\", \n",
    "#         \"LOB\" : \"Favorite-LOB\",\n",
    "#                 }, inplace=True)\n",
    "\n",
    "    \n",
    "    # merging databases\n",
    "    merge_df = pd.merge(df_result_schedule, df_bat, left_index=True, right_index=True)\n",
    "#     df_team[\"key\"] = 1\n",
    "#     merge_df[\"key\"] = 1\n",
    "#     df = pd.merge(df_team, merge_df, on='key')\n",
    "#     del df['key']\n",
    "    \n",
    "    # pulling metrics for the pitchers    \n",
    "    random_number = list(range(len(df)))\n",
    "    \n",
    "    opp_pitch_class = []\n",
    "    opp_pitch_class_2 = []\n",
    "    opp_pitch_class_3 = []\n",
    "    opp_pitch_class_4 = []\n",
    "    opp_pitch_class_5 = []\n",
    "    opp_pitch_class_6 = []\n",
    "    opp_pitch_class_7 = []\n",
    "    opp_pitch_class_8 = []\n",
    "    opp_pitch_class_9 = []\n",
    "    opp_pitch_class_10 = []\n",
    "    opp_pitch_class_11 = []\n",
    "    \n",
    "    for number in random_number:\n",
    "        if df[\"Opposing Pitcher\"][number] in df_pitch.index:\n",
    "            name = df[\"Opposing Pitcher\"][number]\n",
    "            opp_pitch_class.append(df_pitch.loc[name][\"ERA\"])\n",
    "#             opp_pitch_class_2.append(df_pitch.loc[name][\"CG\"])\n",
    "            opp_pitch_class_3.append(df_pitch.loc[name][\"IP\"])\n",
    "            opp_pitch_class_4.append(df_pitch.loc[name][\"ERA+\"])\n",
    "            opp_pitch_class_5.append(df_pitch.loc[name][\"FIP\"])\n",
    "            opp_pitch_class_6.append(df_pitch.loc[name][\"WHIP\"])\n",
    "            opp_pitch_class_7.append(df_pitch.loc[name][\"H9\"])\n",
    "            opp_pitch_class_8.append(df_pitch.loc[name][\"HR9\"])\n",
    "            opp_pitch_class_9.append(df_pitch.loc[name][\"BB9\"])\n",
    "            opp_pitch_class_10.append(df_pitch.loc[name][\"SO9\"])\n",
    "            opp_pitch_class_11.append(df_pitch.loc[name][\"SO/W\"])\n",
    "        else:\n",
    "            opp_pitch_class.append(0)\n",
    "#             opp_pitch_class_2.append(\"N/A\")\n",
    "            opp_pitch_class_3.append(\"N/A\")\n",
    "            opp_pitch_class_4.append(\"N/A\")\n",
    "            opp_pitch_class_5.append(\"N/A\")\n",
    "            opp_pitch_class_6.append(\"N/A\")\n",
    "            opp_pitch_class_7.append(\"N/A\")\n",
    "            opp_pitch_class_8.append(\"N/A\")\n",
    "            opp_pitch_class_9.append(\"N/A\")\n",
    "            opp_pitch_class_10.append(\"N/A\")\n",
    "            opp_pitch_class_11.append(\"N/A\")\n",
    "\n",
    "    start_pitch_class = []\n",
    "    start_pitch_class_2 = []\n",
    "    start_pitch_class_3 = []\n",
    "    start_pitch_class_4 = []\n",
    "    start_pitch_class_5 = []\n",
    "    start_pitch_class_6 = []\n",
    "    start_pitch_class_7 = []\n",
    "    start_pitch_class_8 = []\n",
    "    start_pitch_class_9 = []\n",
    "    start_pitch_class_10 = []\n",
    "    start_pitch_class_11 = []\n",
    "       \n",
    "    for number in random_number:\n",
    "        if df[\"Starting Pitcher\"][number] in df_pitch.index:\n",
    "            name = df[\"Starting Pitcher\"][number]\n",
    "            start_pitch_class.append(df_pitch.loc[name][\"ERA\"])\n",
    "#             start_pitch_class_2.append(df_pitch.loc[name][\"CG\"])\n",
    "            start_pitch_class_3.append(df_pitch.loc[name][\"IP\"])\n",
    "            start_pitch_class_4.append(df_pitch.loc[name][\"ERA+\"])\n",
    "            start_pitch_class_5.append(df_pitch.loc[name][\"FIP\"])\n",
    "            start_pitch_class_6.append(df_pitch.loc[name][\"WHIP\"])\n",
    "            start_pitch_class_7.append(df_pitch.loc[name][\"H9\"])\n",
    "            start_pitch_class_8.append(df_pitch.loc[name][\"HR9\"])\n",
    "            start_pitch_class_9.append(df_pitch.loc[name][\"BB9\"])\n",
    "            start_pitch_class_10.append(df_pitch.loc[name][\"SO9\"])\n",
    "            start_pitch_class_11.append(df_pitch.loc[name][\"SO/W\"])\n",
    "        else:\n",
    "            start_pitch_class.append(0)\n",
    "#             start_pitch_class_2.append(\"N/A\")\n",
    "            start_pitch_class_3.append(\"N/A\")\n",
    "            start_pitch_class_4.append(\"N/A\")\n",
    "            start_pitch_class_5.append(\"N/A\")\n",
    "            start_pitch_class_6.append(\"N/A\")\n",
    "            start_pitch_class_7.append(\"N/A\")\n",
    "            start_pitch_class_8.append(\"N/A\")\n",
    "            start_pitch_class_9.append(\"N/A\")\n",
    "            start_pitch_class_10.append(\"N/A\")\n",
    "            start_pitch_class_11.append(\"N/A\")\n",
    "    \n",
    "    # adding all the pitching metrics\n",
    "    return_df = df\n",
    "    return_df[\"ERA_Starting\"] = start_pitch_class\n",
    "    return_df[\"ERA_Opposing\"] = opp_pitch_class\n",
    "#     return_df[\"CG_Starting\"] = start_pitch_class_2\n",
    "#     return_df[\"CG_Opposing\"] = opp_pitch_class_2\n",
    "    return_df[\"IP_Starting\"] = start_pitch_class_3\n",
    "    return_df[\"IP_Opposing\"] = opp_pitch_class_3\n",
    "    return_df[\"ERA+_Starting \"] = start_pitch_class_4\n",
    "    return_df[\"ERA+_Opposing\"] = opp_pitch_class_4\n",
    "    return_df[\"FIP_Starting\"] = start_pitch_class_5\n",
    "    return_df[\"FIP_Opposing\"] = opp_pitch_class_5\n",
    "    return_df[\"WHIP_Starting\"] = start_pitch_class_6\n",
    "    return_df[\"WHIP_Opposing\"] = opp_pitch_class_6\n",
    "    return_df[\"H9_Starting \"] = start_pitch_class_7\n",
    "    return_df[\"H9_Opposing\"] = opp_pitch_class_7\n",
    "    return_df[\"HR9_Starting\"] = start_pitch_class_8\n",
    "    return_df[\"HR9_Opposing\"] = opp_pitch_class_8\n",
    "    return_df[\"BB9_Starting\"] = start_pitch_class_9\n",
    "    return_df[\"BB9_Opposing\"] = opp_pitch_class_9\n",
    "    return_df[\"SO9_Starting \"] = start_pitch_class_10\n",
    "    return_df[\"SO9_Opposing\"] = opp_pitch_class_10\n",
    "    return_df[\"SO/W_Starting\"] = start_pitch_class_11\n",
    "    return_df[\"SO/W_Opposing\"] = opp_pitch_class_10\n",
    "    \n",
    "    # deleting any rows where pitcher data was not found\n",
    "    return_df = return_df[return_df.HR9_Starting != \"N/A\"]\n",
    "    return_df = return_df[return_df.HR9_Opposing != \"N/A\"]\n",
    "#     return_df = return_df[return_df.ERA_Starting != 0]\n",
    "#     return_df = return_df[return_df.ERA_Opposing != 0]\n",
    "    \n",
    "    # dropping starting and opposing pitcher as we have their metrics now\n",
    "    return_df.drop([\"Starting Pitcher\", \"Opposing Pitcher\"], axis=1, inplace = True)\n",
    "    \n",
    "    # returning dataframe\n",
    "    return return_df\n",
    "\n",
    "\n",
    "def determine_who_wins(starting_pitcher, opposing_pitcher, home_or_away):\n",
    "    \n",
    "    \n",
    "    # gathering pitching data from two inputs in the function\n",
    "    opp_pitch_class = []\n",
    "    opp_pitch_class_2 = []\n",
    "    opp_pitch_class_3 = []\n",
    "    opp_pitch_class_4 = []\n",
    "    opp_pitch_class_5 = []\n",
    "    opp_pitch_class_6 = []\n",
    "    opp_pitch_class_7 = []\n",
    "    opp_pitch_class_8 = []\n",
    "    opp_pitch_class_9 = []\n",
    "    opp_pitch_class_10 = []\n",
    "    opp_pitch_class_11 = []\n",
    "    \n",
    "    if opposing_pitcher in df_pitch.index:\n",
    "        opp_pitch_class.append(df_pitch.loc[opposing_pitcher][\"ERA\"])\n",
    "#         opp_pitch_class_2.append(df_pitch.loc[opposing_pitcher][\"CG\"])\n",
    "        opp_pitch_class_3.append(df_pitch.loc[opposing_pitcher][\"IP\"])\n",
    "        opp_pitch_class_4.append(df_pitch.loc[opposing_pitcher][\"ERA+\"])\n",
    "        opp_pitch_class_5.append(df_pitch.loc[opposing_pitcher][\"FIP\"])\n",
    "        opp_pitch_class_6.append(df_pitch.loc[opposing_pitcher][\"WHIP\"])\n",
    "        opp_pitch_class_7.append(df_pitch.loc[opposing_pitcher][\"H9\"])\n",
    "        opp_pitch_class_8.append(df_pitch.loc[opposing_pitcher][\"HR9\"])\n",
    "        opp_pitch_class_9.append(df_pitch.loc[opposing_pitcher][\"BB9\"])\n",
    "        opp_pitch_class_10.append(df_pitch.loc[opposing_pitcher][\"SO9\"])\n",
    "        opp_pitch_class_11.append(df_pitch.loc[opposing_pitcher][\"SO/W\"])\n",
    "    else:\n",
    "        print(\"Opposing Pitcher Not Found\")\n",
    "\n",
    "    \n",
    "    start_pitch_class = []\n",
    "    start_pitch_class_2 = []\n",
    "    start_pitch_class_3 = []\n",
    "    start_pitch_class_4 = []\n",
    "    start_pitch_class_5 = []\n",
    "    start_pitch_class_6 = []\n",
    "    start_pitch_class_7 = []\n",
    "    start_pitch_class_8 = []\n",
    "    start_pitch_class_9 = []\n",
    "    start_pitch_class_10 = []\n",
    "    start_pitch_class_11 = []\n",
    "       \n",
    "    if starting_pitcher in df_pitch.index:\n",
    "        start_pitch_class.append(df_pitch.loc[starting_pitcher][\"ERA\"])\n",
    "#         start_pitch_class_2.append(df_pitch.loc[starting_pitcher][\"CG\"])\n",
    "        start_pitch_class_3.append(df_pitch.loc[starting_pitcher][\"IP\"])\n",
    "        start_pitch_class_4.append(df_pitch.loc[starting_pitcher][\"ERA+\"])\n",
    "        start_pitch_class_5.append(df_pitch.loc[starting_pitcher][\"FIP\"])\n",
    "        start_pitch_class_6.append(df_pitch.loc[starting_pitcher][\"WHIP\"])\n",
    "        start_pitch_class_7.append(df_pitch.loc[starting_pitcher][\"H9\"])\n",
    "        start_pitch_class_8.append(df_pitch.loc[starting_pitcher][\"HR9\"])\n",
    "        start_pitch_class_9.append(df_pitch.loc[starting_pitcher][\"BB9\"])\n",
    "        start_pitch_class_10.append(df_pitch.loc[starting_pitcher][\"SO9\"])\n",
    "        start_pitch_class_11.append(df_pitch.loc[starting_pitcher][\"SO/W\"])\n",
    "    else:\n",
    "        print(\"Starting Pitcher Not Found\")    \n",
    "        \n",
    "        \n",
    "    # gathering batting metrics from pitchers' team\n",
    "    if opposing_pitcher in team_rooster.index:\n",
    "        opp_team_name = team_rooster.loc[opposing_pitcher][\"Team Name\"]\n",
    "    \n",
    "    if opp_team_name in df_bat.index:\n",
    "        opp_team_metrics = df_bat.loc[opp_team_name]\n",
    "        \n",
    "    opp_team = pd.DataFrame(opp_team_metrics)\n",
    "    opp_team = opp_team.transpose()\n",
    "#     opp_team = opp_team[[\"BatAge\", \"R/G\", \"PA\", \"AB\", \"H\", \"2B\", \"3B\", \"HR\", \"BB\", \"SO\", \"BA\", \"OBP\", \"SLG\", \"OPS\", \"TB\", \"HBP\", \"LOB\"]]\n",
    "    opp_team = opp_team[[\"BatAge\", \"LOB\"]]\n",
    "#     opp_team[\"key\"] = 1\n",
    "\n",
    "#     if starting_pitcher in team_rooster.index:\n",
    "#         team_name = team_rooster.loc[opposing_pitcher][\"Team Name\"]\n",
    "    \n",
    "#     if team_name in df_bat.index:\n",
    "#         team = df_bat.loc[team_name]\n",
    "        \n",
    "#     team = pd.DataFrame(team)\n",
    "#     team = team.transpose()\n",
    "#     team = team[[\"BatAge\", \"R/G\", \"PA\", \"AB\", \"H\", \"2B\", \"3B\", \"HR\", \"BB\", \"SO\", \"BA\", \"OBP\", \"SLG\", \"OPS\", \"TB\", \"HBP\", \"LOB\"]]\n",
    "#     team.rename(columns = {\n",
    "#         \"BatAge\" : \"Favorite-BatAge\", \n",
    "#         \"R/G\" : \"Favorite-R/G\", \n",
    "#         \"PA\" : \"Favorite-PA\", \n",
    "#         \"AB\" : \"Favorite-AB\", \n",
    "#         \"H\" : \"Favorite-H\", \n",
    "#         \"2B\" : \"Favorite-2B\", \n",
    "#         \"3B\" : \"Favorite-3B\", \n",
    "#         \"HR\" : \"Favorite-HR\",\n",
    "#         \"BB\" : \"Favorite-BB\", \n",
    "#         \"SO\" : \"Favorite-SO\", \n",
    "#         \"BA\" : \"Favorite-BA\", \n",
    "#         \"OBP\" : \"Favorite-OBP\", \n",
    "#         \"SLG\" : \"Favorite-SLG\", \n",
    "#         \"OPS\" : \"Favorite-OPS\", \n",
    "#         \"TB\" : \"Favorite-TB\", \n",
    "#         \"HBP\" : \"Favorite-HBP\", \n",
    "#         \"LOB\" : \"Favorite-LOB\",\n",
    "#                 }, inplace=True)\n",
    "#     team[\"key\"] = 1    \n",
    "    \n",
    "    \n",
    "    # gathering distance between teams\n",
    "    distance = get_home_away_distance_in_miles(team_name, opp_team_name)\n",
    "    \n",
    "    if home_or_away == \"Away\":\n",
    "        team[\"Distance\"] = distance\n",
    "    else:\n",
    "        team[\"Distance\"] = (distance * -1)\n",
    "    \n",
    "        \n",
    "    # creating a dataframe to combine all the pitching metrics    \n",
    "    pitching_metrics = pd.DataFrame(\n",
    "    {     \n",
    "        \"ERA-Starting\" : start_pitch_class,\n",
    "        \"ERA-Opposing\" : opp_pitch_class,\n",
    "#         \"CG-Starting\" : start_pitch_class_2,\n",
    "#         \"CG-Opposing\" : opp_pitch_class_2,\n",
    "        \"IP-Starting\" : start_pitch_class_3,\n",
    "        \"IP-Opposing\" : opp_pitch_class_3,\n",
    "        \"ERA+-Starting\" : start_pitch_class_4,\n",
    "        \"ERA+-Opposing\" : opp_pitch_class_4,\n",
    "        \"FIP-Starting\" : start_pitch_class_5,\n",
    "        \"FIP-Opposing\" : opp_pitch_class_5,\n",
    "        \"WHIP-Starting\" : start_pitch_class_6,\n",
    "        \"WHIP-Opposing\" : opp_pitch_class_6,\n",
    "        \"H9-Starting\" : start_pitch_class_7,\n",
    "        \"H9-Opposing\" : opp_pitch_class_7,\n",
    "        \"HR9-Starting\" : start_pitch_class_8,\n",
    "        \"HR9-Opposing\" : opp_pitch_class_8,\n",
    "        \"BB9-Starting\" : start_pitch_class_9,\n",
    "        \"BB9-Opposing\" : opp_pitch_class_9,\n",
    "        \"SO9-Starting\" : start_pitch_class_10,\n",
    "        \"SO9-Opposing\" : opp_pitch_class_10,\n",
    "        \"SO/W-Starting\" : start_pitch_class_11,\n",
    "        \"SO/W-Opposing\" : opp_pitch_class_10,\n",
    "        \"key\" : 1\n",
    "    })\n",
    "    \n",
    "    \n",
    "    # creating test data to run through model\n",
    "#     batting_metrics = pd.merge(team, opp_team, on='key')\n",
    "#     test_data = pd.merge(batting_metrics, pitching_metrics, on=\"key\")\n",
    "    test_data = pd.merge(opp_team, pitching_metrics, on=\"key\")\n",
    "    test_data.drop([\"key\"], axis=1, inplace = True)\n",
    "    \n",
    "    # testing to see what the results look like before running a model\n",
    "    # it works, I can comment this out\n",
    "#     result = test_data\n",
    "    \n",
    "    # running our model\n",
    "    predictions = model.predict(test_data)\n",
    "    \n",
    "    outcome = predictions[0]\n",
    "    \n",
    "    if outcome > 0:\n",
    "        print(\"The Astros will win!\")\n",
    "    else:\n",
    "        print(\"The Astros will lose. :(\")\n",
    "    #printing out our prediction\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_off(df):\n",
    "    df.set_index([\"Player\"], inplace = True)\n",
    "    df = df.groupby(level = 0).mean()\n",
    "    df = df[[\"ERA\", \"WHIP\", \"K\", \"SHO\", \"IP\"]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_off_2(df_result_schedule, df_bat, df_pitch, team):\n",
    "        \n",
    "    # gathering Houston Astros batting averages\n",
    "    df_team = df_bat.loc[team]\n",
    "    df_team = pd.DataFrame(df_team)\n",
    "    df_team = df_team.transpose()\n",
    "    df_team.rename(columns = {\n",
    "        \"BatAge\" : \"Favorite-BatAge\", \n",
    "        \"R/G\" : \"Favorite-R/G\", \n",
    "        \"PA\" : \"Favorite-PA\", \n",
    "        \"AB\" : \"Favorite-AB\", \n",
    "        \"H\" : \"Favorite-H\", \n",
    "        \"2B\" : \"Favorite-2B\", \n",
    "        \"3B\" : \"Favorite-3B\", \n",
    "        \"HR\" : \"Favorite-HR\",\n",
    "        \"BB\" : \"Favorite-BB\", \n",
    "        \"SO\" : \"Favorite-SO\", \n",
    "        \"BA\" : \"Favorite-BA\", \n",
    "        \"OBP\" : \"Favorite-OBP\", \n",
    "        \"SLG\" : \"Favorite-SLG\", \n",
    "        \"OPS\" : \"Favorite-OPS\", \n",
    "        \"TB\" : \"Favorite-TB\", \n",
    "        \"HBP\" : \"Favorite-HBP\", \n",
    "        \"LOB\" : \"Favorite-LOB\",\n",
    "                }, inplace=True)\n",
    "    \n",
    "    # merging databases\n",
    "    merge_df = pd.merge(df_result_schedule, df_bat, left_index=True, right_index=True)\n",
    "    df_team[\"key\"] = 1\n",
    "    merge_df[\"key\"] = 1\n",
    "    df = pd.merge(df_team, merge_df, on='key')\n",
    "    del df['key']\n",
    "    \n",
    "    # pulling metrics for the pitchers    \n",
    "    random_number = list(range(len(df)))\n",
    "    \n",
    "    opp_pitch_class = []\n",
    "    opp_pitch_class_2 = []\n",
    "    opp_pitch_class_3 = []\n",
    "    opp_pitch_class_4 = []\n",
    "    opp_pitch_class_5 = []\n",
    "    \n",
    "    for number in random_number:\n",
    "        if df[\"Opposing Pitcher\"][number] in df_pitch.index:\n",
    "            name = df[\"Opposing Pitcher\"][number]\n",
    "            opp_pitch_class.append(df_pitch.loc[name][\"ERA\"])\n",
    "            opp_pitch_class_2.append(df_pitch.loc[name][\"WHIP\"])\n",
    "            opp_pitch_class_3.append(df_pitch.loc[name][\"K\"])\n",
    "            opp_pitch_class_4.append(df_pitch.loc[name][\"SHO\"])\n",
    "            opp_pitch_class_5.append(df_pitch.loc[name][\"IP\"])\n",
    "\n",
    "        else:\n",
    "            opp_pitch_class.append(0)\n",
    "            opp_pitch_class_2.append(0)\n",
    "            opp_pitch_class_3.append(0)\n",
    "            opp_pitch_class_4.append(0)\n",
    "            opp_pitch_class_5.append(0)\n",
    "\n",
    "\n",
    "    start_pitch_class = []\n",
    "    start_pitch_class_2 = []\n",
    "    start_pitch_class_3 = []\n",
    "    start_pitch_class_4 = []\n",
    "    start_pitch_class_5 = []\n",
    "       \n",
    "    for number in random_number:\n",
    "        if df[\"Starting Pitcher\"][number] in df_pitch.index:\n",
    "            name = df[\"Starting Pitcher\"][number]\n",
    "            start_pitch_class.append(df_pitch.loc[name][\"ERA\"])\n",
    "            start_pitch_class_2.append(df_pitch.loc[name][\"WHIP\"])\n",
    "            start_pitch_class_3.append(df_pitch.loc[name][\"K\"])\n",
    "            start_pitch_class_4.append(df_pitch.loc[name][\"SHO\"])\n",
    "            start_pitch_class_5.append(df_pitch.loc[name][\"IP\"])\n",
    "\n",
    "        else:\n",
    "            start_pitch_class.append(0)\n",
    "            start_pitch_class_2.append(0)\n",
    "            start_pitch_class_3.append(0)\n",
    "            start_pitch_class_4.append(0)\n",
    "            start_pitch_class_5.append(0)\n",
    "\n",
    "    \n",
    "    # adding all the pitching metrics\n",
    "    return_df = df\n",
    "    return_df[\"ERA_Starting\"] = start_pitch_class\n",
    "    return_df[\"ERA_Opposing\"] = opp_pitch_class\n",
    "    return_df[\"CG_Starting\"] = start_pitch_class_2\n",
    "    return_df[\"CG_Opposing\"] = opp_pitch_class_2\n",
    "    return_df[\"IP_Starting\"] = start_pitch_class_3\n",
    "    return_df[\"IP_Opposing\"] = opp_pitch_class_3\n",
    "    return_df[\"ERA+_Starting \"] = start_pitch_class_4\n",
    "    return_df[\"ERA+_Opposing\"] = opp_pitch_class_4\n",
    "    return_df[\"FIP_Starting\"] = start_pitch_class_5\n",
    "    return_df[\"FIP_Opposing\"] = opp_pitch_class_5\n",
    "    \n",
    "    # deleting any rows where pitcher data was not found\n",
    "    return_df = return_df[return_df.ERA_Starting != 0]\n",
    "    return_df = return_df[return_df.ERA_Opposing != 0]\n",
    "    \n",
    "    # dropping starting and opposing pitcher as we have their metrics now\n",
    "    return_df.drop([\"Starting Pitcher\", \"Opposing Pitcher\"], axis=1, inplace = True)\n",
    "    \n",
    "    # returning dataframe\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_who_wins_rotoworld(starting_pitcher, opposing_pitcher, home_or_away):\n",
    "    \n",
    "    \n",
    "    # gathering pitching data from two inputs in the function\n",
    "    opp_pitch_class = []\n",
    "    opp_pitch_class_2 = []\n",
    "    opp_pitch_class_3 = []\n",
    "    opp_pitch_class_4 = []\n",
    "    opp_pitch_class_5 = []\n",
    "    \n",
    "    if opposing_pitcher in df_pitch.index:\n",
    "        opp_pitch_class.append(df_pitch.loc[opposing_pitcher][\"ERA\"])\n",
    "        opp_pitch_class_2.append(df_pitch.loc[opposing_pitcher][\"WHIP\"])\n",
    "        opp_pitch_class_3.append(df_pitch.loc[opposing_pitcher][\"K\"])\n",
    "        opp_pitch_class_4.append(df_pitch.loc[opposing_pitcher][\"SHO\"])\n",
    "        opp_pitch_class_5.append(df_pitch.loc[opposing_pitcher][\"IP\"])\n",
    "\n",
    "\n",
    "    start_pitch_class = []\n",
    "    start_pitch_class_2 = []\n",
    "    start_pitch_class_3 = []\n",
    "    start_pitch_class_4 = []\n",
    "    start_pitch_class_5 = []\n",
    "       \n",
    "    if starting_pitcher in df_pitch.index:\n",
    "        start_pitch_class.append(df_pitch.loc[starting_pitcher][\"ERA\"])\n",
    "        start_pitch_class_2.append(df_pitch.loc[starting_pitcher][\"WHIP\"])\n",
    "        start_pitch_class_3.append(df_pitch.loc[starting_pitcher][\"K\"])\n",
    "        start_pitch_class_4.append(df_pitch.loc[starting_pitcher][\"SHO\"])\n",
    "        start_pitch_class_5.append(df_pitch.loc[starting_pitcher][\"IP\"])\n",
    "    \n",
    "        \n",
    "        \n",
    "    # gathering batting metrics from pitchers' team    \n",
    "    if opposing_pitcher in team_rooster.index:\n",
    "        opp_team_name = team_rooster.loc[opposing_pitcher][\"Team Name\"]\n",
    "    \n",
    "    if opp_team_name in df_bat.index:\n",
    "        opp_team_metrics = df_bat.loc[opp_team_name]\n",
    "        opp_team = pd.DataFrame(opp_team_metrics)\n",
    "        opp_team = opp_team.transpose()\n",
    "        opp_team = opp_team[[\"BatAge\", \"R/G\", \"PA\", \"AB\", \"H\", \"2B\", \"3B\", \"HR\", \"BB\", \"SO\", \"BA\", \"OBP\", \"SLG\", \"OPS\", \"TB\", \"HBP\", \"LOB\"]]\n",
    "        opp_team[\"key\"] = 1\n",
    "\n",
    "    if starting_pitcher in team_rooster.index:\n",
    "        team_name = team_rooster.loc[starting_pitcher][\"Team Name\"]\n",
    "    \n",
    "    if team_name in df_bat.index:\n",
    "        team = df_bat.loc[team_name]\n",
    "        team = pd.DataFrame(team)\n",
    "        team = team.transpose()\n",
    "        team = team[[\"BatAge\", \"R/G\", \"PA\", \"AB\", \"H\", \"2B\", \"3B\", \"HR\", \"BB\", \"SO\", \"BA\", \"OBP\", \"SLG\", \"OPS\", \"TB\", \"HBP\", \"LOB\"]]\n",
    "        team.rename(columns = {\n",
    "        \"BatAge\" : \"Favorite-BatAge\", \n",
    "        \"R/G\" : \"Favorite-R/G\", \n",
    "        \"PA\" : \"Favorite-PA\", \n",
    "        \"AB\" : \"Favorite-AB\", \n",
    "        \"H\" : \"Favorite-H\", \n",
    "        \"2B\" : \"Favorite-2B\", \n",
    "        \"3B\" : \"Favorite-3B\", \n",
    "        \"HR\" : \"Favorite-HR\",\n",
    "        \"BB\" : \"Favorite-BB\", \n",
    "        \"SO\" : \"Favorite-SO\", \n",
    "        \"BA\" : \"Favorite-BA\", \n",
    "        \"OBP\" : \"Favorite-OBP\", \n",
    "        \"SLG\" : \"Favorite-SLG\", \n",
    "        \"OPS\" : \"Favorite-OPS\", \n",
    "        \"TB\" : \"Favorite-TB\", \n",
    "        \"HBP\" : \"Favorite-HBP\", \n",
    "        \"LOB\" : \"Favorite-LOB\",\n",
    "        }, inplace = True)\n",
    "        team[\"key\"] = 1    \n",
    "\n",
    "    \n",
    "    \n",
    "    # gathering distance between teams\n",
    "    distance = get_home_away_distance_in_miles(team_name, opp_team_name)\n",
    "    \n",
    "    if home_or_away == \"Away\":\n",
    "        team[\"Distance\"] = distance\n",
    "    else:\n",
    "        team[\"Distance\"] = (distance * -1)\n",
    "    \n",
    "        \n",
    "    # creating a dataframe to combine all the pitching metrics    \n",
    "    pitching_metrics = pd.DataFrame(\n",
    "    {     \n",
    "        \"ERA_Starting\" : start_pitch_class,\n",
    "        \"ERA_Opposing\" : opp_pitch_class,\n",
    "        \"CG_Starting\" : start_pitch_class_2,\n",
    "        \"CG_Opposing\" : opp_pitch_class_2,\n",
    "        \"IP_Starting\" : start_pitch_class_3,\n",
    "        \"IP_Opposing\" : opp_pitch_class_3,\n",
    "        \"ERA+_Starting\" : start_pitch_class_4,\n",
    "        \"ERA+_Opposing\" : opp_pitch_class_4,\n",
    "        \"FIP_Starting\" : start_pitch_class_5,\n",
    "        \"FIP_Opposing\" : opp_pitch_class_5,\n",
    "        \"key\" : 1\n",
    "    })\n",
    "    \n",
    "    \n",
    "    # creating test data to run through model\n",
    "    batting_metrics = pd.merge(team, opp_team, on='key')\n",
    "    test_data = pd.merge(batting_metrics, pitching_metrics, on=\"key\")\n",
    "    test_data.drop([\"key\"], axis=1, inplace = True)\n",
    "    \n",
    "    # testing to see what the results look like before running a model\n",
    "    # it works, I can comment this out\n",
    "    result = team\n",
    "    \n",
    "    # running our model\n",
    "    result = model.predict(test_data)\n",
    "    \n",
    "    #printing out our prediction\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opposing Pitcher Not Found\n",
      "Starting Pitcher Not Found\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-021e1e8b4fa5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdetermine_who_wins\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Dallas Keuchel\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Chris Bassitt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Home\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-31-897f7ab60f4e>\u001b[0m in \u001b[0;36mdetermine_who_wins\u001b[1;34m(starting_pitcher, opposing_pitcher, home_or_away)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m     \u001b[1;31m# running our model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 467\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    468\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m     \u001b[1;31m#printing out our prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "determine_who_wins(\"Dallas Keuchel\", \"Chris Bassitt\", \"Home\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "determine_who_wins( \"Chris Bassitt\", \"Dallas Keuchel\", \"Away\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Astros will win!\n"
     ]
    }
   ],
   "source": [
    "# Astros vs Mariners 09/23/20\n",
    "determine_who_wins(\"Zack Greinke\", \"Nick Margevicius\", \"Away\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Astros vs Rangers 09/24/20\n",
    "# determine_who_wins(\"Cristian Javier\", \"Lance Lynn\", \"Away\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Astros vs Rangers 09/25/20\n",
    "# determine_who_wins(\"Jose Urquidy\", \"Kyle Cody\", \"Away\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Astros vs Rangers 09/26/20\n",
    "# determine_who_wins(\"Lance McCullers Jr.\", \"Kyle Gibson\", \"Away\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Astros will lose. :(\n"
     ]
    }
   ],
   "source": [
    "# Astros vs Rangers 09/27/20\n",
    "determine_who_wins(\"Chase De Jong\", \"Jordan Lyles\", \"Away\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Astros will win!\n"
     ]
    }
   ],
   "source": [
    "# Astros vs Twins 09/29/20\n",
    "determine_who_wins(\"Zack Greinke\", \"Kenta Maeda\", \"Away\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Astros will lose. :(\n"
     ]
    }
   ],
   "source": [
    "# Astros vs Twins 09/30/20\n",
    "determine_who_wins(\"Jose Urquidy\", \"Jose Berrios\", \"Away\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'opp_team_metrics' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-c64eadb63580>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Minnesota vs Houston prediction Game Day 09/30/20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdetermine_who_wins\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Masahiro Tanaka\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Carlos Carrasco\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Away\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-31-897f7ab60f4e>\u001b[0m in \u001b[0;36mdetermine_who_wins\u001b[1;34m(starting_pitcher, opposing_pitcher, home_or_away)\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[0mopp_team_metrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_bat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mopp_team_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m     \u001b[0mopp_team\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopp_team_metrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m     \u001b[0mopp_team\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopp_team\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m     \u001b[0mopp_team\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopp_team\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"BatAge\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"R/G\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"PA\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"AB\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"H\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"2B\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"3B\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"HR\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"BB\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"SO\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"BA\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"OBP\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"SLG\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"OPS\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"TB\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"HBP\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"LOB\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'opp_team_metrics' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Minnesota vs Houston prediction Game Day 09/30/20\n",
    "determine_who_wins(\"Masahiro Tanaka\", \"Carlos Carrasco\", \"Away\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Minnesota vs Houston prediction Game Day 09/30/20\n",
    "# determine_who_wins(\"Sixto Sanchez\", \"Yu Darvish\", \"Away\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BalancedRandomForestClassifier(random_state=1)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_acry = pd.read_csv(Path(\"../Jack/Resources/team_acry.csv\"))\n",
    "\n",
    "team_rooster = pd.read_csv(Path(\"Data/misc/updated_team_rooster.csv\"))\n",
    "team_rooster.set_index(\"Player Name\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# team_acry.set_index(\"Team_Names\", inplace = True)\n",
    "\n",
    "# new_team_name = []\n",
    "# len_of_active_rooster = list(range(len(team_rooster)))\n",
    "# for number in len_of_active_rooster:\n",
    "#     if team_rooster.iloc[number][\"Team Name\"] in team_acry.index:\n",
    "#         print(team_rooster.iloc[number][\"Team Name\"])\n",
    "#         new_team_name.append(team_acry.loc[team_rooster.iloc[number][\"Team Name\"]][\"Team(New)\"])\n",
    "# #         new_team_name.append(team_acry.loc[number][\"Team(New)\"])\n",
    "#     else:\n",
    "#         new_team_name.append(\"0\")\n",
    "#         if team in team_acry.index:\n",
    "#             new_team_name.append(team_acry.loc[team][\"Team(New)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pitch_2019 = pd.read_csv(Path(\"../Jack/updated pitching data/2019_pitching.csv\"))\n",
    "df_pitch_2018 = pd.read_csv(Path(\"../Jack/updated pitching data/2018_pitching.csv\"))\n",
    "df_pitch_2017 = pd.read_csv(Path(\"../Jack/updated pitching data/2017_pitching.csv\"))\n",
    "df_pitch_2016 = pd.read_csv(Path(\"../Jack/updated pitching data/2016_pitching.csv\"))\n",
    "df_pitch_2015 = pd.read_csv(Path(\"../Jack/updated pitching data/2015_pitching.csv\"))\n",
    "df_pitch_2014 = pd.read_csv(Path(\"../Jack/updated pitching data/2014_pitching.csv\"))\n",
    "df_pitch_2013 = pd.read_csv(Path(\"../Jack/updated pitching data/2013_pitching.csv\"))\n",
    "df_pitch = pd.read_csv(Path(\"../Jack/updated pitching data/2019_pitching.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ERA</th>\n",
       "      <th>CG</th>\n",
       "      <th>IP</th>\n",
       "      <th>ERA+</th>\n",
       "      <th>FIP</th>\n",
       "      <th>WHIP</th>\n",
       "      <th>H9</th>\n",
       "      <th>HR9</th>\n",
       "      <th>BB9</th>\n",
       "      <th>SO9</th>\n",
       "      <th>SO/W</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pitcher</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A.J. Cole</th>\n",
       "      <td>3.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>3.83</td>\n",
       "      <td>1.500</td>\n",
       "      <td>10.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>10.4</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A.J. Minter</th>\n",
       "      <td>7.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>4.61</td>\n",
       "      <td>2.011</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>7.1</td>\n",
       "      <td>10.7</td>\n",
       "      <td>1.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A.J. Puk</th>\n",
       "      <td>3.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>138.0</td>\n",
       "      <td>3.39</td>\n",
       "      <td>1.324</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>2.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AJ Reed</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aaron Altherr</th>\n",
       "      <td>9.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>2.000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ERA   CG    IP   ERA+   FIP   WHIP    H9  HR9  BB9   SO9  SO/W\n",
       "Pitcher                                                                       \n",
       "A.J. Cole      3.81  0.0  26.0  126.0  3.83  1.500  10.7  1.4  2.8  10.4  3.75\n",
       "A.J. Minter    7.06  0.0  29.1   66.0  4.61  2.011  11.0  0.9  7.1  10.7  1.52\n",
       "A.J. Puk       3.18  0.0  11.1  138.0  3.39  1.324   7.9  0.8  4.0  10.3  2.60\n",
       "AJ Reed        0.00  0.0   1.0    NaN  3.21  0.000   0.0  0.0  0.0   0.0   NaN\n",
       "Aaron Altherr  9.00  0.0   1.0   83.0 -0.79  2.000  18.0  0.0  0.0  18.0   NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pitch = clean_pitching_data(df_pitch)\n",
    "df_pitch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pitch = pd.read_csv(Path(\"Data/pitch/pitch_2020.csv\"))\n",
    "# df_pitch.set_index(\"Player\", inplace = True)\n",
    "# df_pitch_2019 = pd.read_csv(Path(\"Data/pitch/pitch_2019.csv\"))\n",
    "# df_pitch_2018 = pd.read_csv(Path(\"Data/pitch/pitch_2018.csv\"))\n",
    "# df_pitch_2017 = pd.read_csv(Path(\"Data/pitch/pitch_2017.csv\"))\n",
    "# df_pitch_2016 = pd.read_csv(Path(\"Data/pitch/pitch_2016.csv\"))\n",
    "# df_pitch_2015 = pd.read_csv(Path(\"Data/pitch/pitch_2015.csv\"))\n",
    "# df_pitch_2014 = pd.read_csv(Path(\"Data/pitch/pitch_2014.csv\"))\n",
    "# df_pitch_2013 = pd.read_csv(Path(\"Data/pitch/pitch_2013.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bat_2019 = pd.read_csv(Path(\"../Jack/Resources/batting_2019.csv\"))\n",
    "df_bat_2018 = pd.read_csv(Path(\"../Jack/Resources/batting_2018.csv\"))\n",
    "df_bat_2017 = pd.read_csv(Path(\"../Jack/Resources/batting_2017.csv\"))\n",
    "df_bat_2016 = pd.read_csv(Path(\"../Jack/Resources/batting_2016.csv\"))\n",
    "df_bat_2015 = pd.read_csv(Path(\"../Jack/Resources/batting_2015.csv\"))\n",
    "df_bat_2014 = pd.read_csv(Path(\"../Jack/Resources/batting_2014.csv\"))\n",
    "df_bat_2013 = pd.read_csv(Path(\"../Jack/Resources/batting_2013.csv\"))\n",
    "df_bat = df_bat_2019\n",
    "# df_bat.set_index(\"Tm\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_batting_data(df_bat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schedule_2019 = pd.read_csv(Path(\"../Jack/Resources/2019_astros_sced.csv\"))\n",
    "df_schedule_2018 = pd.read_csv(Path(\"../Jack/Resources/2018_astros_sced.csv\"))\n",
    "df_schedule_2017 = pd.read_csv(Path(\"../Jack/Resources/2017_astros_sced.csv\"))\n",
    "df_schedule_2016 = pd.read_csv(Path(\"../Jack/Resources/2016_astros_sced.csv\"))\n",
    "df_schedule_2015 = pd.read_csv(Path(\"../Jack/Resources/2015_astros_sced.csv\"))\n",
    "df_schedule_2014 = pd.read_csv(Path(\"../Jack/Resources/2014_astros_sced.csv\"))\n",
    "df_schedule_2013 = pd.read_csv(Path(\"../Jack/Resources/2013_astros_sced.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_home_away_2019 = pd.read_csv(Path(\"../Jack/Resources/2019_home_away.txt\"))\n",
    "df_home_away_2018 = pd.read_csv(Path(\"../Jack/Resources/2018_home_away.txt\"))\n",
    "df_home_away_2017 = pd.read_csv(Path(\"../Jack/Resources/2017_home_away.txt\"))\n",
    "df_home_away_2016 = pd.read_csv(Path(\"../Jack/Resources/2016_home_away.txt\"))\n",
    "df_home_away_2015 = pd.read_csv(Path(\"../Jack/Resources/2015_home_away.txt\"))\n",
    "df_home_away_2014 = pd.read_csv(Path(\"../Jack/Resources/2014_home_away.txt\"))\n",
    "df_home_away_2013 = pd.read_csv(Path(\"../Jack/Resources/2013_home_away.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-7a3cb2d7e3f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mclean_batting_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_bat_2019\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mclean_pitching_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_pitch_2019\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;34m\"HOU\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[0mdf_2019\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-97671049a585>\u001b[0m in \u001b[0;36mcombine_year_df\u001b[1;34m(df_result_schedule, df_bat, df_pitch, team)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;31m# pulling metrics for the pitchers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     \u001b[0mrandom_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[0mopp_pitch_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df_2019 = combine_year_df(\n",
    "    clean_schedule_data(df_schedule_2019,df_home_away_2019), \n",
    "    clean_batting_data(df_bat_2019), \n",
    "    clean_pitching_data(df_pitch_2019),\n",
    "    \"HOU\"\n",
    ")\n",
    "df_2019.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018 = combine_year_df(\n",
    "    clean_schedule_data(df_schedule_2018,df_home_away_2018), \n",
    "    clean_batting_data(df_bat_2018), \n",
    "    clean_pitching_data(df_pitch_2018),\n",
    "    \"HOU\"\n",
    ")\n",
    "df_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017 = combine_year_df(clean_schedule_data(\n",
    "    df_schedule_2017,df_home_away_2017), \n",
    "    clean_batting_data(df_bat_2017), \n",
    "    clean_pitching_data(df_pitch_2017),\n",
    "    \"HOU\"\n",
    ")\n",
    "df_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016 = combine_year_df(clean_schedule_data(\n",
    "    df_schedule_2016,df_home_away_2016), \n",
    "    clean_batting_data(df_bat_2016), \n",
    "    clean_pitching_data(df_pitch_2016),\n",
    "    \"HOU\"\n",
    ")\n",
    "df_2016.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015 = combine_year_df(clean_schedule_data(\n",
    "    df_schedule_2015,df_home_away_2015), \n",
    "    clean_batting_data(df_bat_2015), \n",
    "    clean_pitching_data(df_pitch_2015),    \n",
    "    \"HOU\"\n",
    ")\n",
    "df_2015.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2014 = combine_year_df(clean_schedule_data(\n",
    "    df_schedule_2014,df_home_away_2014), \n",
    "    clean_batting_data(df_bat_2014), \n",
    "    clean_pitching_data(df_pitch_2014),\n",
    "    \"HOU\"\n",
    ")\n",
    "df_2014.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-400777dc7325>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mclean_batting_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_bat_2013\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mclean_pitching_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_pitch_2013\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;34m\"HOU\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[0mdf_2013\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-97671049a585>\u001b[0m in \u001b[0;36mcombine_year_df\u001b[1;34m(df_result_schedule, df_bat, df_pitch, team)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;31m# pulling metrics for the pitchers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     \u001b[0mrandom_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[0mopp_pitch_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df_2013 = combine_year_df(clean_schedule_data(\n",
    "    df_schedule_2013,df_home_away_2013), \n",
    "    clean_batting_data(df_bat_2013), \n",
    "    clean_pitching_data(df_pitch_2013),\n",
    "    \"HOU\"\n",
    ")\n",
    "df_2013.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_2019 = one_off_2(\n",
    "#     clean_schedule_data(df_schedule_2019,df_home_away_2019), \n",
    "#     clean_batting_data(df_bat_2019), \n",
    "#     one_off(df_pitch_2019),\n",
    "#     \"HOU\"\n",
    "# )\n",
    "# df_2019.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_2018 = one_off_2(\n",
    "#     clean_schedule_data(df_schedule_2018,df_home_away_2018), \n",
    "#     clean_batting_data(df_bat_2018), \n",
    "#     one_off(df_pitch_2018),\n",
    "#     \"HOU\"\n",
    "# )\n",
    "# df_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_2017 = one_off_2(\n",
    "#     clean_schedule_data(df_schedule_2017,df_home_away_2017), \n",
    "#     clean_batting_data(df_bat_2017), \n",
    "#     one_off(df_pitch_2017),\n",
    "#     \"HOU\"\n",
    "# )\n",
    "# df_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_2016 = one_off_2(clean_schedule_data(\n",
    "#     df_schedule_2016,df_home_away_2016), \n",
    "#     clean_batting_data(df_bat_2016), \n",
    "#     one_off(df_pitch_2016),\n",
    "#     \"HOU\"\n",
    "# )\n",
    "# df_2016.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_2015 = one_off_2(clean_schedule_data(\n",
    "#     df_schedule_2015,df_home_away_2015), \n",
    "#     clean_batting_data(df_bat_2015), \n",
    "#     one_off(df_pitch_2015),\n",
    "#     \"HOU\"\n",
    "# )\n",
    "# df_2015.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_2014 = one_off_2(clean_schedule_data(\n",
    "#     df_schedule_2014,df_home_away_2014), \n",
    "#     clean_batting_data(df_bat_2014), \n",
    "#     one_off(df_pitch_2014),\n",
    "#     \"HOU\"\n",
    "# )\n",
    "# df_2014.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_2013 = one_off_2(clean_schedule_data(\n",
    "#     df_schedule_2013,df_home_away_2013), \n",
    "#     clean_batting_data(df_bat_2013), \n",
    "#     one_off(df_pitch_2013),\n",
    "#     \"HOU\"\n",
    "# )\n",
    "# df_2013.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n",
      "135\n",
      "136\n",
      "144\n",
      "125\n",
      "157\n",
      "154\n"
     ]
    }
   ],
   "source": [
    "print(len(df_2019))\n",
    "print(len(df_2018))\n",
    "print(len(df_2017))\n",
    "print(len(df_2016))\n",
    "print(len(df_2015))\n",
    "print(len(df_2014))\n",
    "print(len(df_2013))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Favorite-BatAge</th>\n",
       "      <th>Favorite-R/G</th>\n",
       "      <th>Favorite-PA</th>\n",
       "      <th>Favorite-AB</th>\n",
       "      <th>Favorite-H</th>\n",
       "      <th>Favorite-2B</th>\n",
       "      <th>Favorite-3B</th>\n",
       "      <th>Favorite-HR</th>\n",
       "      <th>Favorite-BB</th>\n",
       "      <th>Favorite-SO</th>\n",
       "      <th>...</th>\n",
       "      <th>H9_Starting</th>\n",
       "      <th>H9_Opposing</th>\n",
       "      <th>HR9_Starting</th>\n",
       "      <th>HR9_Opposing</th>\n",
       "      <th>BB9_Starting</th>\n",
       "      <th>BB9_Opposing</th>\n",
       "      <th>SO9_Starting</th>\n",
       "      <th>SO9_Opposing</th>\n",
       "      <th>SO/W_Starting</th>\n",
       "      <th>SO/W_Opposing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.2</td>\n",
       "      <td>4.92</td>\n",
       "      <td>6146.0</td>\n",
       "      <td>5453.0</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.8</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.1</td>\n",
       "      <td>2.30</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.2</td>\n",
       "      <td>4.92</td>\n",
       "      <td>6146.0</td>\n",
       "      <td>5453.0</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>12.1</td>\n",
       "      <td>5.9</td>\n",
       "      <td>7.14</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.2</td>\n",
       "      <td>4.92</td>\n",
       "      <td>6146.0</td>\n",
       "      <td>5453.0</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.7</td>\n",
       "      <td>12.1</td>\n",
       "      <td>10.5</td>\n",
       "      <td>7.14</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.2</td>\n",
       "      <td>4.92</td>\n",
       "      <td>6146.0</td>\n",
       "      <td>5453.0</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>13.8</td>\n",
       "      <td>11.1</td>\n",
       "      <td>6.79</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.2</td>\n",
       "      <td>4.92</td>\n",
       "      <td>6146.0</td>\n",
       "      <td>5453.0</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.3</td>\n",
       "      <td>11.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.71</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>25.8</td>\n",
       "      <td>3.77</td>\n",
       "      <td>6020.0</td>\n",
       "      <td>5457.0</td>\n",
       "      <td>1307.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.8</td>\n",
       "      <td>11.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>7.2</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2.37</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>25.8</td>\n",
       "      <td>3.77</td>\n",
       "      <td>6020.0</td>\n",
       "      <td>5457.0</td>\n",
       "      <td>1307.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.9</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.94</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>25.8</td>\n",
       "      <td>3.77</td>\n",
       "      <td>6020.0</td>\n",
       "      <td>5457.0</td>\n",
       "      <td>1307.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.5</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.9</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1.90</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>25.8</td>\n",
       "      <td>3.77</td>\n",
       "      <td>6020.0</td>\n",
       "      <td>5457.0</td>\n",
       "      <td>1307.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.4</td>\n",
       "      <td>13.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2.08</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>25.8</td>\n",
       "      <td>3.77</td>\n",
       "      <td>6020.0</td>\n",
       "      <td>5457.0</td>\n",
       "      <td>1307.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.8</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>7.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.37</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004 rows  58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Favorite-BatAge  Favorite-R/G  Favorite-PA  Favorite-AB  Favorite-H  \\\n",
       "0                28.2          4.92       6146.0       5453.0      1390.0   \n",
       "1                28.2          4.92       6146.0       5453.0      1390.0   \n",
       "2                28.2          4.92       6146.0       5453.0      1390.0   \n",
       "3                28.2          4.92       6146.0       5453.0      1390.0   \n",
       "4                28.2          4.92       6146.0       5453.0      1390.0   \n",
       "...               ...           ...          ...          ...         ...   \n",
       "1129             25.8          3.77       6020.0       5457.0      1307.0   \n",
       "1130             25.8          3.77       6020.0       5457.0      1307.0   \n",
       "1131             25.8          3.77       6020.0       5457.0      1307.0   \n",
       "1132             25.8          3.77       6020.0       5457.0      1307.0   \n",
       "1133             25.8          3.77       6020.0       5457.0      1307.0   \n",
       "\n",
       "      Favorite-2B  Favorite-3B  Favorite-HR  Favorite-BB  Favorite-SO  ...  \\\n",
       "0           278.0         18.0        205.0        565.0       1197.0  ...   \n",
       "1           278.0         18.0        205.0        565.0       1197.0  ...   \n",
       "2           278.0         18.0        205.0        565.0       1197.0  ...   \n",
       "3           278.0         18.0        205.0        565.0       1197.0  ...   \n",
       "4           278.0         18.0        205.0        565.0       1197.0  ...   \n",
       "...           ...          ...          ...          ...          ...  ...   \n",
       "1129        266.0         16.0        148.0        426.0       1535.0  ...   \n",
       "1130        266.0         16.0        148.0        426.0       1535.0  ...   \n",
       "1131        266.0         16.0        148.0        426.0       1535.0  ...   \n",
       "1132        266.0         16.0        148.0        426.0       1535.0  ...   \n",
       "1133        266.0         16.0        148.0        426.0       1535.0  ...   \n",
       "\n",
       "      H9_Starting   H9_Opposing  HR9_Starting  HR9_Opposing  BB9_Starting  \\\n",
       "0              8.8          9.8           1.2           2.2           3.3   \n",
       "1              5.5          9.5           1.5           2.0           1.7   \n",
       "2              5.5          7.8           1.5           1.2           1.7   \n",
       "3              6.0          8.8           1.2           1.9           2.0   \n",
       "4              8.3         11.1           1.3           2.6           1.5   \n",
       "...            ...          ...           ...           ...           ...   \n",
       "1129          10.8         11.6           1.2           1.7           3.0   \n",
       "1130           6.9          8.2           0.5           1.5           5.3   \n",
       "1131          10.5          8.2           1.1           1.5           3.1   \n",
       "1132           8.4         13.3           1.6           1.7           4.0   \n",
       "1133          10.8          9.9           1.2           1.1           3.0   \n",
       "\n",
       "      BB9_Opposing  SO9_Starting   SO9_Opposing  SO/W_Starting  SO/W_Opposing  \n",
       "0              3.4            7.5           7.1           2.30            7.1  \n",
       "1              4.4           12.1           5.9           7.14            5.9  \n",
       "2              2.7           12.1          10.5           7.14           10.5  \n",
       "3              2.8           13.8          11.1           6.79           11.1  \n",
       "4              3.7            8.8           8.0           5.71            8.0  \n",
       "...            ...            ...           ...            ...            ...  \n",
       "1129           3.3            7.2           9.2           2.37            9.2  \n",
       "1130           2.7            5.0           8.9           0.94            8.9  \n",
       "1131           2.7            5.9           8.9           1.90            8.9  \n",
       "1132           3.0            8.3           4.7           2.08            4.7  \n",
       "1133           2.3            7.2           6.1           2.37            6.1  \n",
       "\n",
       "[1004 rows x 58 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(Path(\"Data/complete_dataframes/2013_2019_Astros_full_new_pitch_data.csv\"))\n",
    "result = df\n",
    "result.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Favorite-BatAge</th>\n",
       "      <th>Favorite-R/G</th>\n",
       "      <th>Favorite-PA</th>\n",
       "      <th>Favorite-AB</th>\n",
       "      <th>Favorite-H</th>\n",
       "      <th>Favorite-2B</th>\n",
       "      <th>Favorite-3B</th>\n",
       "      <th>Favorite-HR</th>\n",
       "      <th>Favorite-BB</th>\n",
       "      <th>Favorite-SO</th>\n",
       "      <th>...</th>\n",
       "      <th>H9_Starting</th>\n",
       "      <th>H9_Opposing</th>\n",
       "      <th>HR9_Starting</th>\n",
       "      <th>HR9_Opposing</th>\n",
       "      <th>BB9_Starting</th>\n",
       "      <th>BB9_Opposing</th>\n",
       "      <th>SO9_Starting</th>\n",
       "      <th>SO9_Opposing</th>\n",
       "      <th>SO/W_Starting</th>\n",
       "      <th>SO/W_Opposing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.2</td>\n",
       "      <td>4.92</td>\n",
       "      <td>6146.0</td>\n",
       "      <td>5453.0</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.8</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.2</td>\n",
       "      <td>4.92</td>\n",
       "      <td>6146.0</td>\n",
       "      <td>5453.0</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>12.1</td>\n",
       "      <td>5.9</td>\n",
       "      <td>7.14</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.2</td>\n",
       "      <td>4.92</td>\n",
       "      <td>6146.0</td>\n",
       "      <td>5453.0</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.7</td>\n",
       "      <td>12.1</td>\n",
       "      <td>10.5</td>\n",
       "      <td>7.14</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.2</td>\n",
       "      <td>4.92</td>\n",
       "      <td>6146.0</td>\n",
       "      <td>5453.0</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>13.8</td>\n",
       "      <td>11.1</td>\n",
       "      <td>6.79</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.2</td>\n",
       "      <td>4.92</td>\n",
       "      <td>6146.0</td>\n",
       "      <td>5453.0</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.3</td>\n",
       "      <td>11.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8</td>\n",
       "      <td>5.71</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>25.8</td>\n",
       "      <td>3.77</td>\n",
       "      <td>6020.0</td>\n",
       "      <td>5457.0</td>\n",
       "      <td>1307.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.8</td>\n",
       "      <td>11.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>7.2</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2.37</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>25.8</td>\n",
       "      <td>3.77</td>\n",
       "      <td>6020.0</td>\n",
       "      <td>5457.0</td>\n",
       "      <td>1307.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.9</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.94</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>25.8</td>\n",
       "      <td>3.77</td>\n",
       "      <td>6020.0</td>\n",
       "      <td>5457.0</td>\n",
       "      <td>1307.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.5</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.9</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>25.8</td>\n",
       "      <td>3.77</td>\n",
       "      <td>6020.0</td>\n",
       "      <td>5457.0</td>\n",
       "      <td>1307.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.4</td>\n",
       "      <td>13.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2.08</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>25.8</td>\n",
       "      <td>3.77</td>\n",
       "      <td>6020.0</td>\n",
       "      <td>5457.0</td>\n",
       "      <td>1307.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.8</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>7.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.37</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004 rows  58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Favorite-BatAge  Favorite-R/G  Favorite-PA  Favorite-AB  Favorite-H  \\\n",
       "0               28.2          4.92       6146.0       5453.0      1390.0   \n",
       "1               28.2          4.92       6146.0       5453.0      1390.0   \n",
       "2               28.2          4.92       6146.0       5453.0      1390.0   \n",
       "3               28.2          4.92       6146.0       5453.0      1390.0   \n",
       "4               28.2          4.92       6146.0       5453.0      1390.0   \n",
       "..               ...           ...          ...          ...         ...   \n",
       "157             25.8          3.77       6020.0       5457.0      1307.0   \n",
       "158             25.8          3.77       6020.0       5457.0      1307.0   \n",
       "159             25.8          3.77       6020.0       5457.0      1307.0   \n",
       "160             25.8          3.77       6020.0       5457.0      1307.0   \n",
       "161             25.8          3.77       6020.0       5457.0      1307.0   \n",
       "\n",
       "     Favorite-2B  Favorite-3B  Favorite-HR  Favorite-BB  Favorite-SO  ...  \\\n",
       "0          278.0         18.0        205.0        565.0       1197.0  ...   \n",
       "1          278.0         18.0        205.0        565.0       1197.0  ...   \n",
       "2          278.0         18.0        205.0        565.0       1197.0  ...   \n",
       "3          278.0         18.0        205.0        565.0       1197.0  ...   \n",
       "4          278.0         18.0        205.0        565.0       1197.0  ...   \n",
       "..           ...          ...          ...          ...          ...  ...   \n",
       "157        266.0         16.0        148.0        426.0       1535.0  ...   \n",
       "158        266.0         16.0        148.0        426.0       1535.0  ...   \n",
       "159        266.0         16.0        148.0        426.0       1535.0  ...   \n",
       "160        266.0         16.0        148.0        426.0       1535.0  ...   \n",
       "161        266.0         16.0        148.0        426.0       1535.0  ...   \n",
       "\n",
       "     H9_Starting   H9_Opposing  HR9_Starting  HR9_Opposing  BB9_Starting  \\\n",
       "0             8.8          9.8           1.2           2.2           3.3   \n",
       "1             5.5          9.5           1.5             2           1.7   \n",
       "2             5.5          7.8           1.5           1.2           1.7   \n",
       "3               6          8.8           1.2           1.9             2   \n",
       "4             8.3         11.1           1.3           2.6           1.5   \n",
       "..            ...          ...           ...           ...           ...   \n",
       "157          10.8         11.6           1.2           1.7             3   \n",
       "158           6.9          8.2           0.5           1.5           5.3   \n",
       "159          10.5          8.2           1.1           1.5           3.1   \n",
       "160           8.4         13.3           1.6           1.7             4   \n",
       "161          10.8          9.9           1.2           1.1             3   \n",
       "\n",
       "     BB9_Opposing  SO9_Starting   SO9_Opposing  SO/W_Starting  SO/W_Opposing  \n",
       "0             3.4            7.5           7.1            2.3            7.1  \n",
       "1             4.4           12.1           5.9           7.14            5.9  \n",
       "2             2.7           12.1          10.5           7.14           10.5  \n",
       "3             2.8           13.8          11.1           6.79           11.1  \n",
       "4             3.7            8.8             8           5.71              8  \n",
       "..            ...            ...           ...            ...            ...  \n",
       "157           3.3            7.2           9.2           2.37            9.2  \n",
       "158           2.7              5           8.9           0.94            8.9  \n",
       "159           2.7            5.9           8.9            1.9            8.9  \n",
       "160             3            8.3           4.7           2.08            4.7  \n",
       "161           2.3            7.2           6.1           2.37            6.1  \n",
       "\n",
       "[1004 rows x 58 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frames = [df_2019.iloc[50:125],\n",
    "#           df_2018.iloc[50:125],\n",
    "#           df_2017.iloc[50:125], \n",
    "#           df_2016.iloc[50:125],\n",
    "#           df_2015.iloc[50:125], \n",
    "#           df_2014.iloc[50:125], \n",
    "#           df_2013.iloc[50:125]]\n",
    "\n",
    "# frames = [df_2019.iloc[50:125],\n",
    "#           df_2018.iloc[50:125],\n",
    "#           df_2017.iloc[50:125], \n",
    "#           df_2016.iloc[50:125],\n",
    "#           df_2015.iloc[50:125], \n",
    "#           df_2014.iloc[50:125], \n",
    "#           df_2013.iloc[50:125]]\n",
    "\n",
    "frames = [df_2019,\n",
    "          df_2018,\n",
    "          df_2017, \n",
    "          df_2016,\n",
    "          df_2015, \n",
    "          df_2014, \n",
    "          df_2013]\n",
    "\n",
    "# frames = [df_2019.iloc[50:125],\n",
    "#           df_2018.iloc[50:125],\n",
    "#           df_2017.iloc[50:125], \n",
    "#           df_2016.iloc[50:125],\n",
    "#           df_2015.iloc[50:125], \n",
    "#           df_2014.iloc[50:125], \n",
    "#           df_2013.iloc[50:125]]\n",
    "\n",
    "result = pd.concat(frames)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Favorite-BatAge\n",
      "Favorite-R/G\n",
      "Favorite-PA\n",
      "Favorite-AB\n",
      "Favorite-H\n",
      "Favorite-2B\n",
      "Favorite-3B\n",
      "Favorite-HR\n",
      "Favorite-BB\n",
      "Favorite-SO\n",
      "Favorite-BA\n",
      "Favorite-OBP\n",
      "Favorite-SLG\n",
      "Favorite-OPS\n",
      "Favorite-TB\n",
      "Favorite-HBP\n",
      "Favorite-LOB\n",
      "Result\n",
      "Distance\n",
      "BatAge\n",
      "R/G\n",
      "PA\n",
      "AB\n",
      "H\n",
      "2B\n",
      "3B\n",
      "HR\n",
      "BB\n",
      "SO\n",
      "BA\n",
      "OBP\n",
      "SLG\n",
      "OPS\n",
      "TB\n",
      "HBP\n",
      "LOB\n",
      "ERA_Starting\n",
      "ERA_Opposing\n",
      "CG_Starting\n",
      "CG_Opposing\n",
      "IP_Starting\n",
      "IP_Opposing\n",
      "ERA+_Starting \n",
      "ERA+_Opposing\n",
      "FIP_Starting\n",
      "FIP_Opposing\n",
      "WHIP_Starting\n",
      "WHIP_Opposing\n",
      "H9_Starting \n",
      "H9_Opposing\n",
      "HR9_Starting\n",
      "HR9_Opposing\n",
      "BB9_Starting\n",
      "BB9_Opposing\n",
      "SO9_Starting \n",
      "SO9_Opposing\n",
      "SO/W_Starting\n",
      "SO/W_Opposing\n"
     ]
    }
   ],
   "source": [
    "for col in result.columns: \n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result[result.HR9_Starting != \"N/A\"]\n",
    "result = result[result.HR9_Opposing != \"N/A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(Path(\"Data/complete_dataframes/2013_2019_Astros_full_new_pitch_data.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d.to_csv(Path(\"Data/complete_dataframes/testtt.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(Path(\"Data/complete_dataframes/2013_2019_Astros_full.csv\"))\n",
    "result = df\n",
    "result.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = result.copy()\n",
    "X.drop([\"Result\"], axis=1, inplace=True)\n",
    "# X.dropna(inplace = True)\n",
    "\n",
    "y = result[\"Result\"].ravel()\n",
    "# y.dropna(inplace = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=87)\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "X_scaler.fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.53      0.64      0.50      0.58      0.57      0.33       126\n",
      "          1       0.62      0.50      0.64      0.56      0.57      0.32       145\n",
      "\n",
      "avg / total       0.58      0.57      0.58      0.57      0.57      0.32       271\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "model = BalancedRandomForestClassifier(random_state=1)\n",
    "model = model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "results = pd.DataFrame({\"Prediction\": predictions,\"Actual\": y_test}).reset_index(drop=True)\n",
    "confusion_matrix(y_test, predictions)\n",
    "\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "results = pd.DataFrame({\"Prediction\": predictions,\n",
    "                        \"Actual\": y_test}).reset_index(drop=True)\n",
    "acc_1 = balanced_accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.51      0.48       126\n",
      "           1       0.53      0.48      0.50       145\n",
      "\n",
      "    accuracy                           0.49       271\n",
      "   macro avg       0.49      0.49      0.49       271\n",
      "weighted avg       0.49      0.49      0.49       271\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree, preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = tree.DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "results = pd.DataFrame({\"Prediction\": predictions,\n",
    "                        \"Actual\": y_test}).reset_index(drop=True)\n",
    "acc_2 = balanced_accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "acc_3 = accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=45, activation='relu'))\n",
    "# model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "# model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type float).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[1;34m(element)\u001b[0m\n\u001b[0;32m     92\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mspec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_spec_from_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_fallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36mtype_spec_from_value\u001b[1;34m(element, use_fallback)\u001b[0m\n\u001b[0;32m    465\u001b[0m   raise TypeError(\"Could not build a TypeSpec for %r with type %s\" %\n\u001b[1;32m--> 466\u001b[1;33m                   (element, type(element).__name__))\n\u001b[0m\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not build a TypeSpec for      Favorite-BatAge  Favorite-R/G  Favorite-PA  Favorite-AB  Favorite-H  \\\n0               28.2          4.92       6146.0       5453.0      1390.0   \n1               28.2          4.92       6146.0       5453.0      1390.0   \n2               28.2          4.92       6146.0       5453.0      1390.0   \n3               28.2          4.92       6146.0       5453.0      1390.0   \n4               28.2          4.92       6146.0       5453.0      1390.0   \n..               ...           ...          ...          ...         ...   \n157             25.8          3.77       6020.0       5457.0      1307.0   \n158             25.8          3.77       6020.0       5457.0      1307.0   \n159             25.8          3.77       6020.0       5457.0      1307.0   \n160             25.8          3.77       6020.0       5457.0      1307.0   \n161             25.8          3.77       6020.0       5457.0      1307.0   \n\n     Favorite-2B  Favorite-3B  Favorite-HR  Favorite-BB  Favorite-SO  ...  \\\n0          278.0         18.0        205.0        565.0       1197.0  ...   \n1          278.0         18.0        205.0        565.0       1197.0  ...   \n2          278.0         18.0        205.0        565.0       1197.0  ...   \n3          278.0         18.0        205.0        565.0       1197.0  ...   \n4          278.0         18.0        205.0        565.0       1197.0  ...   \n..           ...          ...          ...          ...          ...  ...   \n157        266.0         16.0        148.0        426.0       1535.0  ...   \n158        266.0         16.0        148.0        426.0       1535.0  ...   \n159        266.0         16.0        148.0        426.0       1535.0  ...   \n160        266.0         16.0        148.0        426.0       1535.0  ...   \n161        266.0         16.0        148.0        426.0       1535.0  ...   \n\n     H9_Starting   H9_Opposing  HR9_Starting  HR9_Opposing  BB9_Starting  \\\n0             8.8          9.8           1.2           2.2           3.3   \n1             5.5          9.5           1.5             2           1.7   \n2             5.5          7.8           1.5           1.2           1.7   \n3               6          8.8           1.2           1.9             2   \n4             8.3         11.1           1.3           2.6           1.5   \n..            ...          ...           ...           ...           ...   \n157          10.8         11.6           1.2           1.7             3   \n158           6.9          8.2           0.5           1.5           5.3   \n159          10.5          8.2           1.1           1.5           3.1   \n160           8.4         13.3           1.6           1.7             4   \n161          10.8          9.9           1.2           1.1             3   \n\n     BB9_Opposing  SO9_Starting   SO9_Opposing  SO/W_Starting  SO/W_Opposing  \n0             3.4            7.5           7.1            2.3            7.1  \n1             4.4           12.1           5.9           7.14            5.9  \n2             2.7           12.1          10.5           7.14           10.5  \n3             2.8           13.8          11.1           6.79           11.1  \n4             3.7            8.8             8           5.71              8  \n..            ...            ...           ...            ...            ...  \n157           3.3            7.2           9.2           2.37            9.2  \n158           2.7              5           8.9           0.94            8.9  \n159           2.7            5.9           8.9            1.9            8.9  \n160             3            8.3           4.7           2.08            4.7  \n161           2.3            7.2           6.1           2.37            6.1  \n\n[1004 rows x 57 columns] with type DataFrame",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-9bc0671a27bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1061\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[0;32m   1064\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m       \u001b[1;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1117\u001b[1;33m         model=model)\n\u001b[0m\u001b[0;32m   1118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[0mindices_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"batch\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mslice_inputs\u001b[1;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[0;32m    388\u001b[0m     dataset = dataset_ops.DatasetV2.zip((\n\u001b[0;32m    389\u001b[0m         \u001b[0mindices_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m         \u001b[0mdataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m     ))\n\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensors\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    602\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m     \"\"\"\n\u001b[1;32m--> 604\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    605\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, element)\u001b[0m\n\u001b[0;32m   2980\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2981\u001b[0m     \u001b[1;34m\"\"\"See `Dataset.from_tensors()` for details.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2982\u001b[1;33m     \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2983\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_structure\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2984\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[1;34m(element)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;31m# the value. As a fallback try converting the value to a tensor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         normalized_components.append(\n\u001b[1;32m---> 98\u001b[1;33m             ops.convert_to_tensor(t, name=\"component_%d\" % i))\n\u001b[0m\u001b[0;32m     99\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensorSpec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1499\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1501\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    336\u001b[0m                                          as_ref=False):\n\u001b[0;32m    337\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    262\u001b[0m   \"\"\"\n\u001b[0;32m    263\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[1;32m--> 264\u001b[1;33m                         allow_broadcast=True)\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    273\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tf.constant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m   \u001b[1;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m   \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=300, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 471us/step - loss: 2.9761 - accuracy: 0.6146\n",
      "Accuracy: 61.46\n"
     ]
    }
   ],
   "source": [
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "results = pd.DataFrame({\"Prediction\": predictions,\n",
    "                        \"Actual\": y_test}).reset_index(drop=True)\n",
    "acc_4 = balanced_accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LogReg_clf = LogisticRegression(solver = \"lbfgs\", random_state = 78,  max_iter = 1000000)\n",
    "\n",
    "LogReg_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = LogReg_clf.predict(X_test)\n",
    "\n",
    "acc_5 =  accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg_clf = LogisticRegression(solver = \"newton-cg\", random_state = 78,  max_iter = 1000000)\n",
    "\n",
    "LogReg_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = LogReg_clf.predict(X_test)\n",
    "\n",
    "acc_6 =  accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver = \"saga\", random_state = 78,  max_iter = 1000000)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "acc_7 =  accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg_clf = LogisticRegression(solver = \"liblinear\", random_state = 78,  max_iter = 1000000)\n",
    "\n",
    "LogReg_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = LogReg_clf.predict(X_test)\n",
    "\n",
    "acc_8 =  accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_scores = [acc_1, acc_2, acc_3, acc_4, acc_5, acc_6, acc_7, acc_8]\n",
    "model_names = [\"BalancedRandomForestClassifier\", \"DecisionTreeClassifier\", \"XGBClassifier\", \"KNeighborsClassifier\", \"LogisticRegression-LBFGS\", \"LogisticRegression-Newton\", \"LogisticRegression-Saga\", \"LogisticRegression-Liblinear\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score_df = pd.DataFrame({\"Models\" : model_names,\n",
    "                            \"Accuracy Scores\" : acc_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score_df.set_index(\"Models\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score_df.sort_values(\"Accuracy Scores\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Accuracy Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BalancedRandomForestClassifier</td>\n",
       "      <td>0.573153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.491899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.542435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.546743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression-LBFGS</td>\n",
       "      <td>0.616236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression-Newton</td>\n",
       "      <td>0.623616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression-Saga</td>\n",
       "      <td>0.612546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression-Liblinear</td>\n",
       "      <td>0.630996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Models  Accuracy Scores\n",
       "0  BalancedRandomForestClassifier         0.573153\n",
       "1          DecisionTreeClassifier         0.491899\n",
       "2                   XGBClassifier         0.542435\n",
       "3            KNeighborsClassifier         0.546743\n",
       "4        LogisticRegression-LBFGS         0.616236\n",
       "5       LogisticRegression-Newton         0.623616\n",
       "6         LogisticRegression-Saga         0.612546\n",
       "7    LogisticRegression-Liblinear         0.630996"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='1421'>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"06acb4e7-6a8a-4709-862f-adf492bb1159\" data-root-id=\"1421\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  function embed_document(root) {\n",
       "  var docs_json = {\"d074a34e-3042-43bc-a0e4-8a78d65c6174\":{\"roots\":{\"references\":[{\"attributes\":{\"source\":{\"id\":\"1455\"}},\"id\":\"1462\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1433\",\"type\":\"CategoricalScale\"},{\"attributes\":{\"axis_label\":\"Models\",\"bounds\":\"auto\",\"formatter\":{\"id\":\"1466\"},\"major_label_orientation\":\"horizontal\",\"ticker\":{\"id\":\"1440\"}},\"id\":\"1439\",\"type\":\"CategoricalAxis\"},{\"attributes\":{\"data\":{\"Accuracy_Scores\":{\"__ndarray__\":\"jwbKWURX4j9CqDQnR3vfPzBj+YihW+E/EkRty+t+4T9BlX7mNLjjP3ZNcgmq9OM/J7kEVfqZ4z+rBWYsHzHkPw==\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[8]},\"Models\":[\"BalancedRandomForestClassifier\",\"DecisionTreeClassifier\",\"XGBClassifier\",\"KNeighborsClassifier\",\"LogisticRegression-LBFGS\",\"LogisticRegression-Newton\",\"LogisticRegression-Saga\",\"LogisticRegression-Liblinear\"]},\"selected\":{\"id\":\"1456\"},\"selection_policy\":{\"id\":\"1472\"}},\"id\":\"1455\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1446\",\"type\":\"ResetTool\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b3\"},\"height\":{\"value\":0.8},\"right\":{\"field\":\"Accuracy_Scores\"},\"y\":{\"field\":\"Models\"}},\"id\":\"1458\",\"type\":\"HBar\"},{\"attributes\":{},\"id\":\"1466\",\"type\":\"CategoricalTickFormatter\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b3\"},\"height\":{\"value\":0.8},\"line_alpha\":{\"value\":0.1},\"right\":{\"field\":\"Accuracy_Scores\"},\"y\":{\"field\":\"Models\"}},\"id\":\"1459\",\"type\":\"HBar\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.2},\"fill_color\":{\"value\":\"#1f77b3\"},\"height\":{\"value\":0.8},\"line_alpha\":{\"value\":0.2},\"right\":{\"field\":\"Accuracy_Scores\"},\"y\":{\"field\":\"Models\"}},\"id\":\"1460\",\"type\":\"HBar\"},{\"attributes\":{},\"id\":\"1444\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"children\":[{\"id\":\"1422\"},{\"id\":\"1426\"},{\"id\":\"1483\"}],\"margin\":[0,0,0,0],\"name\":\"Row02621\",\"tags\":[\"embedded\"]},\"id\":\"1421\",\"type\":\"Row\"},{\"attributes\":{},\"id\":\"1463\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"align\":null,\"below\":[{\"id\":\"1435\"}],\"center\":[{\"id\":\"1438\"},{\"id\":\"1441\"}],\"left\":[{\"id\":\"1439\"}],\"margin\":null,\"min_border_bottom\":10,\"min_border_left\":10,\"min_border_right\":10,\"min_border_top\":10,\"plot_height\":300,\"plot_width\":700,\"renderers\":[{\"id\":\"1461\"}],\"sizing_mode\":\"fixed\",\"title\":{\"id\":\"1427\"},\"toolbar\":{\"id\":\"1448\"},\"x_range\":{\"id\":\"1423\"},\"x_scale\":{\"id\":\"1431\"},\"y_range\":{\"id\":\"1424\"},\"y_scale\":{\"id\":\"1433\"}},\"id\":\"1426\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1436\",\"type\":\"BasicTicker\"},{\"attributes\":{\"axis\":{\"id\":\"1439\"},\"dimension\":1,\"grid_line_color\":null,\"ticker\":null},\"id\":\"1441\",\"type\":\"Grid\"},{\"attributes\":{\"axis_label\":\"Accuracy Scores\",\"bounds\":\"auto\",\"formatter\":{\"id\":\"1463\"},\"major_label_orientation\":\"horizontal\",\"ticker\":{\"id\":\"1436\"}},\"id\":\"1435\",\"type\":\"LinearAxis\"},{\"attributes\":{\"text\":\"Accuracy Scores After Refinment\",\"text_color\":{\"value\":\"black\"},\"text_font_size\":{\"value\":\"12pt\"}},\"id\":\"1427\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1442\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"1456\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1431\",\"type\":\"LinearScale\"},{\"attributes\":{\"overlay\":{\"id\":\"1447\"}},\"id\":\"1445\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1443\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1472\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"factors\":[\"BalancedRandomForestClassifier\",\"DecisionTreeClassifier\",\"XGBClassifier\",\"KNeighborsClassifier\",\"LogisticRegression-LBFGS\",\"LogisticRegression-Newton\",\"LogisticRegression-Saga\",\"LogisticRegression-Liblinear\"],\"tags\":[[[\"Models\",\"Models\",null]]]},\"id\":\"1424\",\"type\":\"FactorRange\"},{\"attributes\":{\"margin\":[5,5,5,5],\"name\":\"HSpacer02626\",\"sizing_mode\":\"stretch_width\"},\"id\":\"1483\",\"type\":\"Spacer\"},{\"attributes\":{\"data_source\":{\"id\":\"1455\"},\"glyph\":{\"id\":\"1458\"},\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1460\"},\"nonselection_glyph\":{\"id\":\"1459\"},\"selection_glyph\":null,\"view\":{\"id\":\"1462\"}},\"id\":\"1461\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1440\",\"type\":\"CategoricalTicker\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1447\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"margin\":[5,5,5,5],\"name\":\"HSpacer02625\",\"sizing_mode\":\"stretch_width\"},\"id\":\"1422\",\"type\":\"Spacer\"},{\"attributes\":{\"axis\":{\"id\":\"1435\"},\"grid_line_color\":null,\"ticker\":null},\"id\":\"1438\",\"type\":\"Grid\"},{\"attributes\":{\"end\":0.6449060121143083,\"reset_end\":0.6449060121143083,\"reset_start\":0.0,\"tags\":[[[\"Accuracy Scores\",\"Accuracy Scores\",null]]]},\"id\":\"1423\",\"type\":\"Range1d\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1425\"},{\"id\":\"1442\"},{\"id\":\"1443\"},{\"id\":\"1444\"},{\"id\":\"1445\"},{\"id\":\"1446\"}]},\"id\":\"1448\",\"type\":\"Toolbar\"},{\"attributes\":{\"callback\":null,\"renderers\":[{\"id\":\"1461\"}],\"tags\":[\"hv_created\"],\"tooltips\":[[\"Models\",\"@{Models}\"],[\"Accuracy Scores\",\"@{Accuracy_Scores}\"]]},\"id\":\"1425\",\"type\":\"HoverTool\"}],\"root_ids\":[\"1421\"]},\"title\":\"Bokeh Application\",\"version\":\"2.1.1\"}};\n",
       "  var render_items = [{\"docid\":\"d074a34e-3042-43bc-a0e4-8a78d65c6174\",\"root_ids\":[\"1421\"],\"roots\":{\"1421\":\"06acb4e7-6a8a-4709-862f-adf492bb1159\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "  }\n",
       "if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);</script>"
      ],
      "text/plain": [
       ":Bars   [Models]   (Accuracy Scores)"
      ]
     },
     "execution_count": 95,
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "1421"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_score_df.hvplot.barh(x=\"Models\", y=\"Accuracy Scores\", figsize = (20,10), title = \"Accuracy Scores After Refinment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5617529880478087"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "acc =  accuracy_score(y_test, y_pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv = pd.read_csv(Path(\"Data/misc/test_pitch_df.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv.set_index(\"Player\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>CG</th>\n",
       "      <th>SHO</th>\n",
       "      <th>IP</th>\n",
       "      <th>H</th>\n",
       "      <th>ER</th>\n",
       "      <th>K</th>\n",
       "      <th>BB</th>\n",
       "      <th>HR</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>SV</th>\n",
       "      <th>BS</th>\n",
       "      <th>HLD</th>\n",
       "      <th>ERA</th>\n",
       "      <th>WHIP</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A.J. Cole</th>\n",
       "      <td>28.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.00</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.810</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A.J. Minter</th>\n",
       "      <td>27.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.10</td>\n",
       "      <td>36.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.060</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A.J. Puk</th>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.180</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aaron Barrett</th>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.430</td>\n",
       "      <td>3.86</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aaron Brooks</th>\n",
       "      <td>30.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.65</td>\n",
       "      <td>59.0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>41.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.595</td>\n",
       "      <td>1.37</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Age     G   GS   CG  SHO     IP     H    ER     K    BB    HR  \\\n",
       "Player                                                                          \n",
       "A.J. Cole      28.0  25.0  0.0  0.0  0.0  26.00  31.0  11.0  30.0   8.0   4.0   \n",
       "A.J. Minter    27.0  36.0  0.0  0.0  0.0  29.10  36.0  23.0  35.0  23.0   3.0   \n",
       "A.J. Puk       25.0  10.0  0.0  0.0  0.0  11.10  10.0   4.0  13.0   5.0   1.0   \n",
       "Aaron Barrett  32.0   3.0  0.0  0.0  0.0   2.10   5.0   4.0   1.0   4.0   1.0   \n",
       "Aaron Brooks   30.0  14.5  9.0  0.0  0.0  54.65  59.0  34.5  41.0  17.0  10.5   \n",
       "\n",
       "                 W    L   SV   BS  HLD     ERA  WHIP  class  \n",
       "Player                                                       \n",
       "A.J. Cole      3.0  1.0  1.0  0.0  0.0   3.810  1.50      0  \n",
       "A.J. Minter    3.0  4.0  5.0  2.0  6.0   7.060  2.01      0  \n",
       "A.J. Puk       2.0  0.0  0.0  1.0  2.0   3.180  1.32      0  \n",
       "Aaron Barrett  0.0  0.0  0.0  0.0  0.0  15.430  3.86      0  \n",
       "Aaron Brooks   3.0  4.0  0.0  0.0  0.0   5.595  1.37      2  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test_csv.copy()\n",
    "X.drop(columns = \"class\", inplace=True)\n",
    "\n",
    "y = test_csv[\"class\"].ravel()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=87)\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "X_scaler.fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>CG</th>\n",
       "      <th>SHO</th>\n",
       "      <th>IP</th>\n",
       "      <th>H</th>\n",
       "      <th>ER</th>\n",
       "      <th>K</th>\n",
       "      <th>BB</th>\n",
       "      <th>HR</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>SV</th>\n",
       "      <th>BS</th>\n",
       "      <th>HLD</th>\n",
       "      <th>ERA</th>\n",
       "      <th>WHIP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A.J. Cole</th>\n",
       "      <td>28.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.00</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.810</td>\n",
       "      <td>1.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A.J. Minter</th>\n",
       "      <td>27.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.10</td>\n",
       "      <td>36.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.060</td>\n",
       "      <td>2.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A.J. Puk</th>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.180</td>\n",
       "      <td>1.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aaron Barrett</th>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.430</td>\n",
       "      <td>3.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aaron Brooks</th>\n",
       "      <td>30.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.65</td>\n",
       "      <td>59.0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>41.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.595</td>\n",
       "      <td>1.370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zack Britton</th>\n",
       "      <td>32.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.10</td>\n",
       "      <td>38.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.910</td>\n",
       "      <td>1.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zack Godley</th>\n",
       "      <td>30.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.00</td>\n",
       "      <td>48.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>35.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.165</td>\n",
       "      <td>1.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zack Greinke</th>\n",
       "      <td>36.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.10</td>\n",
       "      <td>87.5</td>\n",
       "      <td>34.0</td>\n",
       "      <td>93.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.960</td>\n",
       "      <td>1.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zack Littell</th>\n",
       "      <td>24.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.00</td>\n",
       "      <td>34.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.680</td>\n",
       "      <td>1.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zack Wheeler</th>\n",
       "      <td>30.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.10</td>\n",
       "      <td>196.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.960</td>\n",
       "      <td>1.260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>773 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Age     G    GS   CG  SHO      IP      H    ER      K    BB  \\\n",
       "Player                                                                        \n",
       "A.J. Cole      28.0  25.0   0.0  0.0  0.0   26.00   31.0  11.0   30.0   8.0   \n",
       "A.J. Minter    27.0  36.0   0.0  0.0  0.0   29.10   36.0  23.0   35.0  23.0   \n",
       "A.J. Puk       25.0  10.0   0.0  0.0  0.0   11.10   10.0   4.0   13.0   5.0   \n",
       "Aaron Barrett  32.0   3.0   0.0  0.0  0.0    2.10    5.0   4.0    1.0   4.0   \n",
       "Aaron Brooks   30.0  14.5   9.0  0.0  0.0   54.65   59.0  34.5   41.0  17.0   \n",
       "...             ...   ...   ...  ...  ...     ...    ...   ...    ...   ...   \n",
       "Zack Britton   32.0  66.0   0.0  0.0  0.0   61.10   38.0  13.0   53.0  32.0   \n",
       "Zack Godley    30.0  16.5   4.5  0.0  0.0   46.00   48.0  30.5   35.0  21.0   \n",
       "Zack Greinke   36.0  16.5  16.5  0.0  0.0  104.10   87.5  34.0   93.5  15.0   \n",
       "Zack Littell   24.0  29.0   0.0  0.0  0.0   37.00   34.0  11.0   32.0   9.0   \n",
       "Zack Wheeler   30.0  31.0  31.0  0.0  0.0  195.10  196.0  86.0  195.0  50.0   \n",
       "\n",
       "                 HR     W    L   SV   BS   HLD     ERA   WHIP  \n",
       "Player                                                         \n",
       "A.J. Cole       4.0   3.0  1.0  1.0  0.0   0.0   3.810  1.500  \n",
       "A.J. Minter     3.0   3.0  4.0  5.0  2.0   6.0   7.060  2.010  \n",
       "A.J. Puk        1.0   2.0  0.0  0.0  1.0   2.0   3.180  1.320  \n",
       "Aaron Barrett   1.0   0.0  0.0  0.0  0.0   0.0  15.430  3.860  \n",
       "Aaron Brooks   10.5   3.0  4.0  0.0  0.0   0.0   5.595  1.370  \n",
       "...             ...   ...  ...  ...  ...   ...     ...    ...  \n",
       "Zack Britton    3.0   3.0  1.0  3.0  4.0  29.0   1.910  1.140  \n",
       "Zack Godley     7.0   2.0  2.5  1.0  0.0   0.0   5.165  1.455  \n",
       "Zack Greinke   10.5   9.0  2.5  0.0  0.0   0.0   2.960  1.010  \n",
       "Zack Littell    4.0   6.0  0.0  0.0  1.0   1.0   2.680  1.160  \n",
       "Zack Wheeler   22.0  11.0  8.0  0.0  0.0   0.0   3.960  1.260  \n",
       "\n",
       "[773 rows x 18 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-971aad6bd0aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Splitting into Train and Test sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Creating StandardScaler instance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "# Splitting into Train and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Creating StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fitting Standard Scaller\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scaling data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Create a random forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=500, random_state=1)\n",
    "\n",
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Making predictions using the testing data\n",
    "predictions = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculating the confusion matrix\n",
    "# cm = confusion_matrix(y_test, predictions)\n",
    "# cm_df = pd.DataFrame(\n",
    "#     cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    "# )\n",
    "\n",
    "# Calculating the accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Random Forests in sklearn will automatically calculate feature importance\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "# We can sort the features by their importance\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)\n",
    "\n",
    "# Visualize the features by importance\n",
    "importances_df = pd.DataFrame(sorted(zip(rf_model.feature_importances_, X.columns), reverse=True))\n",
    "importances_df.set_index(importances_df[1], inplace=True)\n",
    "importances_df.drop(columns=1, inplace=True)\n",
    "importances_df.rename(columns={0: 'Feature Importances'}, inplace=True)\n",
    "importances_sorted = importances_df.sort_values(by='Feature Importances')\n",
    "importances_sorted.plot(kind='barh', color='lightgreen', title= 'Features Importances', legend=False, figsize = [10 , 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
